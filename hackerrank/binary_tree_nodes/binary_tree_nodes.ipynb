{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('binary_tree_nodes').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,2), (3,2), (6,8), (9,8), (2,5), (8,5), (5, None)]\n",
    "schema = StructType([\n",
    "    StructField(\"N\", IntegerType(), False),\n",
    "    StructField(\"P\", IntegerType(), True)\n",
    "])\n",
    "bst = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|  N|   P|\n",
      "+---+----+\n",
      "|  1|   2|\n",
      "|  3|   2|\n",
      "|  6|   8|\n",
      "|  9|   8|\n",
      "|  2|   5|\n",
      "|  8|   5|\n",
      "|  5|null|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_list = bst.rdd.map(lambda row: (row.N, row.P)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Leaf'), (3, 'Leaf'), (6, 'Leaf'), (9, 'Leaf'), (2, 'Inner'), (8, 'Inner'), (5, 'Root'), (5, 'Inner')]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for row in bst_list:\n",
    "    if row[1] == None:\n",
    "        result.append((row[0], 'Root'))\n",
    "    n = row[0]\n",
    "    inner = False\n",
    "    for i in range(len(bst_list)):\n",
    "        if bst_list[i][1] == n:\n",
    "            inner = True\n",
    "    result.append((n, 'Inner')) if inner else result.append((n, 'Leaf'))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|  N|N Type|\n",
      "+---+------+\n",
      "|  1|  Leaf|\n",
      "|  3|  Leaf|\n",
      "|  6|  Leaf|\n",
      "|  9|  Leaf|\n",
      "|  2| Inner|\n",
      "|  8| Inner|\n",
      "|  5|  Root|\n",
      "|  5| Inner|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = spark.createDataFrame(data=result, schema=StructType([StructField('N', IntegerType(), False), StructField('N Type', StringType(), False)]))\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
